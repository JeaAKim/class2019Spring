{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP (Natural Language process _자연어처리)\n",
    "\n",
    ":is a part of computer science and artificial intelligence which deals with human languages.\n",
    ": 주로 text processing 에 관여한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " OS 의 기능: 외부에서 어떤 파일을 불러 올 때 os를 이용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'a man in the house' # untokenized string\n",
    "t = ['a', 'man', 'in', 'the', 'house'] # tokenized seqeuence of words as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'man', 'in', 'the', 'house']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t =s.split()\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".Text 함수는 기존의 str 이었던 변수의 type 을 <class 'nltk.text.Text'>로 변환한다\n",
    "이는 nltk 전용 variable로 변환함을 의미한다. 이렇게 하면 nltk 속에 있는 여러 함수의 기능을 적용가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "<Text: a man in the house...>\n"
     ]
    }
   ],
   "source": [
    "a = nltk.Text(t)\n",
    "print(type(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Text: a man in the house...>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=nltk.Text(s.split())\n",
    "print(type(b))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.getcwd() \n",
    "get the path of current working directory\n",
    "\n",
    "는 현재 스크립트의 실행경로를 나타낸다 즉 현재 디렉토리에서 받아오는 함수를 보여준다.\n",
    "디렉토리는 파일이 정리되어 쌓여있는 저장공간을 의미한다. 여기에서는 현재 디렉토리 속에 포함되어있는\n",
    "06_01.txt 파일을 받아오라는 명령이다. (+r? 컴퓨터 내에서 full path로 생각하면 된다)\n",
    "\n",
    "encoding = utf8\"\n",
    "text는 다양한 encoding이 존재한다. 현재 디렉토리에 저장된 파일은 ut8로 되어있음! \n",
    "\n",
    "그런 파일을 .read( ) 하면 불러온다. \n",
    "파일명 부분 (06_01.txt)먼 바꾸면 그 파일명이 나오게 할 수 있다\n",
    "\n",
    "여기까지 하면 raw 에 그파일이 들어오게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(os.getcwd()+r'/06_01.txt', encoding = 'utf8').read()\n",
    "# raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 word 가 아닌 character 하나하나를 말함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1154507\n",
      "The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it\n"
     ]
    }
   ],
   "source": [
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word_toknize 함수\n",
    "\n",
    ": raw text를 받았을 때, nltk 속에 split 보다 세련된 word_tokenize 함수를 사용해본다\n",
    "결과 값은 단어의 수와 비슷할 것이다.  띄어쓰기 단위로  tokenize 했기 때문이다.\n",
    "\n",
    "※ split 으로 할 경우, \n",
    "colon 이 단어 바로 뒤에 붙어서 쪼갤 수 없는것과 다르게, word_tokenize 함수를 쓰면 이것도 떼어낼 수 있다.※"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "257726\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by', 'Fyodor', 'Dostoevsky', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', 'Title', ':', 'Crime', 'and', 'Punishment', 'Author', ':', 'Fyodor', 'Dostoevsky', 'Release', 'Date', ':', 'March', '28', ',', '2006', '[', 'EBook', '#', '2554', ']', 'Last', 'Updated', ':', 'October', '27', ',', '2016', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', '***', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "token 은 list 로 나온다. 그것을 다시 nltk 속에 있는 text 함수로 받게 되면?\n",
    ": <class 'nltk.text.Text> 는 nltk 전용 variable로 만들졌음을 의미한다\n",
    "\n",
    "Q. 왜 nltk 전용 variable을 만들고 나면 좋은가? \n",
    "그 속에 있는 nltk 함수들을 적용시킬 수 있기 때문이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text[:10])\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text.collocations() 를 쓰면\n",
    "\n",
    "두 단어가 같이 pair로 자주 나올 가능성이 높음을 보여준다. \n",
    "여기서는 사람 이름. 다른 곳에서는 숙어 일 수도 있고..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concordance 함수를 쓰면\n",
    "\n",
    "쓰는 방법은 (찾고자하는 단어,width,line) 으로 입력하면 된다.\n",
    "뜻을 풀이하면, text 전체 중에서 great 가 보이는 것들은 전체 spotting 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      "and were more frequent in periods of great strain . In 1859 he was allowed to r\n",
      "ndency and of late she had read with great interest a book she got through Mr. \n",
      " the bosom of her family ... . And a great deal more ... . Quite excusable , si\n",
      "that you had heard that Dounia had a great deal to put up with in the Svidrigra\n",
      "g will she has . Dounia can endure a great deal and even in the most difficult \n",
      " that letter she reproached him with great heat and indignation for the basenes\n",
      "putation ; they had seen and known a great deal more than Mr. Svidrigailov had \n",
      "n other people ’ s . In my opinion a great deal , a very great deal of all this\n",
      " In my opinion a great deal , a very great deal of all this was unnecessary ; b\n",
      " . He is a very busy man and is in a great hurry to get to Petersburg , so that\n",
      " me that , though he is not a man of great education , he is clever and seems t\n",
      " very well . Of course , there is no great love either on his side , or on hers\n",
      "tted the matter has been arranged in great haste . Besides he is a man of great\n",
      "great haste . Besides he is a man of great prudence and he will see , to be sur\n",
      "d that she is ready to put up with a great deal , if only their future relation\n",
      " off for Petersburg , where he has a great deal of business , and he wants to o\n",
      "a or I breathed a word to him of the great hopes we have of his helping us to p\n",
      "ites that ‘ Dounia can put up with a great deal. ’ I know that very well . I kn\n",
      "at , that ‘ Dounia can put up with a great deal. ’ If she could put up with Mr.\n",
      "it , she certainly can put up with a great deal . And now mother and she have t\n",
      "e young , and she was walking in the great heat bareheaded and with no parasol \n",
      "f the skirt , close to the waist : a great piece was rent and hanging loose . A\n",
      "ts or conversations . He worked with great intensity without sparing himself , \n",
      " uproarious and was reputed to be of great physical strength . One night , when\n",
      ". His legs felt suddenly heavy and a great drowsiness came upon him . He turned\n"
     ]
    }
   ],
   "source": [
    "text.concordance('great',79, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "폴더 속에 유용하게 쓸 수 있는 예제 데이터를 가지고 있는 경우도 있다. \n",
    "'melville-moby_dick.txt' 가 그중 하나이다. corpus(말뭉치) 가 담겨 있는 폴더 내에서 ~~ 해서 불러 오는 것이다.\n",
    "\n",
    "결국 raw 에 text str이 들어와 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Moby Dick by Herman Melville 1851]\r\n",
      "\r\n",
      "\r\n",
      "ETYMOLOGY.\r\n",
      "\r\n",
      "(Supplied by a Late Consumptive Usher to a Grammar School)\r\n",
      "\r\n",
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\r\n",
      "now.  He was\n"
     ]
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "print(raw[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fdist 는 frequency distribution이다. 여기서는 아까 만들었던 text와는 다르고, 그냥 str 그 자체이다.\n",
    "어떤 것이 얼마나 자주 나오는지 보여주는 역할을 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 198098), ('e', 115855), ('t', 85539), ('a', 75266), ('o', 68338), ('n', 64431), ('s', 62022), ('i', 61891), ('h', 61434), ('r', 51311), ('l', 41893), ('d', 37468), ('u', 26457), ('\\r', 22924), ('\\n', 22924), ('m', 22525), ('c', 21360), ('w', 20917), ('g', 20180), ('f', 20029), (',', 19229), ('y', 16542), ('p', 16207), ('b', 15451), ('v', 8427), ('k', 7882), ('.', 7558), ('-', 5984), (';', 4173), ('I', 3543), ('\"', 3071), (\"'\", 2922), ('A', 2650), ('T', 2457), ('S', 2209), ('!', 1767), ('H', 1462), ('B', 1426), ('W', 1305), ('E', 1237), ('q', 1234), ('N', 1186), ('C', 1147), ('P', 1048), ('x', 1007), ('?', 1004), ('O', 988), ('L', 900), ('j', 829), ('R', 823)]\n"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(raw)\n",
    "print(fdist.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for loop는 리스트에 적용된다. \n",
    "\n",
    "★for loop 해석 시에는 반드시 in 이하를 먼저 찾는다.★\n",
    "in raw 즉, raw 속에서 하나씩 들어갈 때 ch 로 들어간다. 그런데 그 밑에 if 조건을 넣고 돌아가는 형식이다. \n",
    "ch 가 알파벳이면~ 그걸 리스트로 만드는데 lower 해서 만들어라.라는 의미이다.\n",
    "\n",
    "★중요★ most common 이 주는 것은 단순히 list가 아닌 tuple이다. 그래서 두개가 한번에 다섯번 도는셈이다.\n",
    "for loop가 두개를 가지고 pair로 도는 셈이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', 105049), ('t', 80836), ('a', 74052), ('o', 72238), ('n', 63157)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 't', 'a', 'o', 'n']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "print(fdist.most_common(5))\n",
    "\n",
    "[char for (char, count) in fdist.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zymosis',\n",
       " 'zymosterol',\n",
       " 'zymosthenic',\n",
       " 'zymotechnic',\n",
       " 'zymotechnical',\n",
       " 'zymotechnics',\n",
       " 'zymotechny',\n",
       " 'zymotic',\n",
       " 'zymotically',\n",
       " 'zymotize',\n",
       " 'zymotoxic',\n",
       " 'zymurgy',\n",
       " 'Zyrenian',\n",
       " 'Zyrian',\n",
       " 'Zyryan',\n",
       " 'zythem',\n",
       " 'Zythia',\n",
       " 'zythum',\n",
       " 'Zyzomys']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.words.words('en')[-20:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.words.words('en'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
